#Red Teaming AI Resources

### Offsec ML Playbook
A database of offensive ML TTPâ€™s, broken down by supply chain attacks, offensive ML techniques, and adversarial ML. The playbook aims to simplify the decision-making process of targeting ML in an organization.

[Offsec ML Playbook](https://5stars217.github.io/2023-10-26-introducing-offsec-ml-framework/)

### LLM Security
LLM security is the investigation of the failure modes of LLMs in use, the conditions that lead to them, and their mitigations.

Here are links to large language model security content - research, papers, and news - posted by [@llm_sec](https://llmsecurity.net/).

- [Chat with LLMs](https://chat.lmsys.org/)

### AWS Sagemaker

[AWS Sagemaker Documentation](https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#page01)

### LLM Testing Findings

[LLM Testing Findings](https://github.com/BishopFox/llm-testing-findings/tree/main)

### Awesome LLM Security
A curation of awesome tools, documents, and projects about LLM Security.

[Awesome LLM Security](https://github.com/corca-ai/awesome-llm-security)

### Baseline Defenses for Adversarial Attacks Against Aligned Language Models
Official code for "Baseline Defenses for Adversarial Attacks Against Aligned Language Models."

[Baseline Defenses](https://github.com/neelsjain/baseline-defenses)

### GitHub Copilot Chat: From Prompt Injection to Data Exfiltration

[GitHub Copilot Chat](https://kai-greshake.de/)

### Embrace the Red Blog

[Embrace the Red Blog](https://embracethered.com/blog/)

Some notable 2024 blogs from the Embrace the Red blog:

- [LLM Context Pollution and Delayed Automated Tool Invocation](https://embracethered.com/blog/posts/2024/llm-context-pollution-and-delayed-automated-tool-invocation/)
- [GitHub Copilot Chat: Prompt Injection & Data Exfiltration](https://embracethered.com/blog/posts/2024/github-copilot-chat-prompt-injection-data-exfiltration/)
- [WhoAmI: Conditional Prompt Injection Instructions](https://embracethered.com/blog/posts/2024/whoami-conditional-prompt-injection-instructions/)
- [Machine Learning Attack Series: Keras Backdoor Model](https://embracethered.com/blog/posts/2024/machine-learning-attack-series-keras-backdoor-model/)

### Awesome Backdoor in Deep Learning
This GitHub repository provides a curated list of papers and resources on backdoor attacks and defenses in deep learning. It includes information on backdoor attacks in various contexts, such as image classification and language models, and links to relevant papers and code.

[Awesome-Backdoor-in-Deep-Learning](https://github.com/zihao-ai/Awesome-Backdoor-in-Deep-Learning)

### Offensive AI Compilation
This repository offers a collection of resources related to offensive AI, including tools for performing backdoor attacks. It includes frameworks like ART, Cleverhans, and TextAttack, which support various attack types and data formats.

[Offensive AI Compilation](https://github.com/jiep/offensive-ai-compilation)

### Backdoor Learning Resources
This GitHub repository lists multiple resources related to backdoor learning, including papers, tools, and datasets. It covers various types of backdoor attacks and defenses, providing a comprehensive overview of the field.

[Backdoor Learning Resources](https://github.com/THUYimingLi/backdoor-learning-resources)

### Chat-Models-Backdoor-Attacking
This repository contains code for implementing backdoor attacks on chat models. It includes methods for training and deploying chat models with distributed trigger-based backdoor attacks, which are designed to be triggered by specific user inputs across different conversation rounds.

[Chat-Models-Backdoor-Attacking](https://github.com/hychaochao/Chat-Models-Backdoor-Attacking)

### Label Consistent Backdoor
This repository focuses on creating models with imperceptible triggers using adversarial perturbations. It includes a detailed methodology for implementing backdoor attacks using the CIFAR-10 dataset and the ResNet-18 model.

[Label Consistent Backdoor](https://github.com/AhmadSavaiz03/Label_Consistent_Backdoor)

These resources should provide you with a good starting point for understanding and implementing backdoor attacks in AI models.

### Additional Resources

- [OWASP LLM AI Security and Governance Checklist](https://owasp.org/www-project-top-10-for-large-language-model-applications/llm-top-10-governance-doc/LLM_AI_Security_and_Governance_Checklist-v1.1.pdf)
- [NIST AI 100-2E 2023](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)
- [Microsoft AI Bug Bar](https://www.microsoft.com/en-us/msrc/aibugbar)
- [MITRE ATLAS](https://atlas.mitre.org/matrices/ATLAS/)

### White Paper Summaries and Analysis

[Red Teaming AI - GitHub Repository](https://raw.githubusercontent.com/pjcampbe11/Red-Teaming-AI/main/README.md)

**Rigging**  
[https://github.com/dreadnode/rigging](https://github.com/dreadnode/rigging)

**Marque**  
[https://github.com/dreadnode/marque](https://github.com/dreadnode/marque)

**Parley**  
[https://github.com/dreadnode/Parley](https://github.com/dreadnode/Parley)

**Research**  
[https://github.com/dreadnode/research](https://github.com/dreadnode/research)

**Counterfit**  
[https://github.com/Azure/counterfit](https://github.com/Azure/counterfit)

**Proof Pudding**  
[https://github.com/moohax/Proof-Pudding](https://github.com/moohax/Proof-Pudding)

**Koppeling**  
[https://github.com/monoxgas/Koppeling](https://github.com/monoxgas/Koppeling)

**sRDI**  
[https://github.com/monoxgas/sRDI](https://github.com/monoxgas/sRDI)

**Deep Drop**  
[https://github.com/moohax/Deep-Drop](https://github.com/moohax/Deep-Drop)

**Charcuterie**  
[https://github.com/moohax/Charcuterie](https://github.com/moohax/Charcuterie)

**Minibus**  
[https://github.com/monoxgas/minibus](https://github.com/monoxgas/minibus)

**Offensive Machine Learning - Apres Con (Slides)**  
[https://github.com/dreadnode/conferences/blob/main/ApesCyber_2024/workshop/Offensive%20Machine%20Learning.pdf](https://github.com/dreadnode/conferences/blob/main/ApesCyber_2024/workshop/Offensive%20Machine%20Learning.pdf)

**Offensive Machine Learning - Apres Con (Notebooks)**  
[https://github.com/dreadnode/conferences/tree/main/ApesCyber_2024/workshop/notebooks](https://github.com/dreadnode/conferences/tree/main/ApesCyber_2024/workshop/notebooks)

**Ghosts on the Node (Slides)**  
[https://github.com/dreadnode/conferences/blob/main/SOCON_2024/Ghosts%20on%20the%20Node.pdf](https://github.com/dreadnode/conferences/blob/main/SOCON_2024/Ghosts%20on%20the%20Node.pdf)

**Zen and the Art of Adversarial Machine Learning (Slides)**  
[https://github.com/moohax/Talks/blob/master/slides/Blackhat_EU_21.pdf](https://github.com/moohax/Talks/blob/master/slides/Blackhat_EU_21.pdf)

**Zen and the Art of Adversarial Machine Learning (Talk)**  
[https://www.youtube.com/watch?v=tEBwMGCKEso](https://www.youtube.com/watch?v=tEBwMGCKEso)

**Screendoors on Battleships (Slides)**  
[https://github.com/moohax/Talks/blob/master/slides/Screen%20Doors%20on%20Battleships.pdf](https://github.com/moohax/Talks/blob/master/slides/Screen%20Doors%20on%20Battleships.pdf)

**Counterfit: Attacking Machine Learning in Blackbox Settings (Slides)**  
[https://github.com/moohax/Talks/blob/master/slides/Counterfit_BH_Arsenal_21.pdf](https://github.com/moohax/Talks/blob/master/slides/Counterfit_BH_Arsenal_21.pdf)

**It Is The Year 2000, We Are Robots (Slides)**  
[https://github.com/moohax/Talks/blob/master/slides/bsides_slc_20.pdf](https://github.com/moohax/Talks/blob/master/slides/bsides_slc_20.pdf)

**Flying A False Flag (Slides)**  
[https://github.com/monoxgas/FlyingAFalseFlag/blob/master/nick_landers_bhusa_19_flying_a_false_flag.pdf](https://github.com/monoxgas/FlyingAFalseFlag/blob/master/nick_landers_bhusa_19_flying_a_false_flag.pdf)

**42: The Answer to Life the Universe, and Everything Offensive Security (Slides)**  
[https://github.com/moohax/Talks/blob/master/slides/DerbyCon19.pdf](https://github.com/moohax/Talks/blob/master/slides/DerbyCon19.pdf)

**Scheming With Machines (Slides)**  
[https://github.com/moohax/Talks/blob/master/slides/Scheming_with_Machines_BSidesLV_19.pdf](https://github.com/moohax/Talks/blob/master/slides/Scheming_with_Machines_BSidesLV_19.pdf)

**Poisoning Web-Scale Training Datasets is Practical**  
[https://arxiv.org/abs/2302.10149](https://arxiv.org/abs/2302.10149)

**Sandbox Classification Using Decision Trees and Artificial Neural Networks**  
[https://link.springer.com/chapter/10.1007/978-3-030-52249-0_18](https://link.springer.com/chapter/10.1007/978-3-030-52249-0_18)
