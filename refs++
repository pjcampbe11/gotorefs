Offsec ML Playbook
A database of offensive ML TTPâ€™s, broken down by supply chain attacks, offensive ML techniques and adversarial ML. The playbook aims to simplify the decision making process of targetting ML in an organization.

https://5stars217.github.io/2023-10-26-introducing-offsec-ml-framework/

LLM security is the investigation of the failure modes of LLMs in use, the conditions that lead to them, and their mitigations.

Here are links to large language model security content - research, papers, and news - posted by @llm_sec

https://llmsecurity.net/

Chat with LLms - https://chat.lmsys.org/

LLM testing findings

https://github.com/BishopFox/llm-testing-findings/tree/main

A curation of awesome tools, documents and projects about LLM Security.

https://github.com/corca-ai/awesome-llm-security

Official Code for "Baseline Defenses for Adversarial Attacks Against Aligned Language Models

https://github.com/neelsjain/baseline-defenses

GitHub Copilot Chat: From Prompt Injection to Data Exfiltration

https://kai-greshake.de/

https://embracethered.com/blog/

https://owasp.org/www-project-top-10-for-large-language-model-applications/llm-top-10-governance-doc/LLM_AI_Security_and_Governance_Checklist-v1.1.pdf

https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf

https://www.microsoft.com/en-us/msrc/aibugbar

https://atlas.mitre.org/matrices/ATLAS/
